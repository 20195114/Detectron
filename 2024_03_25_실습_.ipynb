{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOr/GdKifTmsQP3F6qJahU4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/20195114/Detectron/blob/main/2024_03_25_%EC%8B%A4%EC%8A%B5_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "import pandas as pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ORwJdNODVfH",
        "outputId": "d2f58501-2c97-42f8-c043-b4e7c34c5f18"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pYIsaYwt7YAz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f8dc795-c2e2-4539-98f9-f147b06472e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5391 entries, 0 to 5390\n",
            "Data columns (total 7 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   Date       5391 non-null   object \n",
            " 1   Open       5385 non-null   float64\n",
            " 2   High       5385 non-null   float64\n",
            " 3   Low        5385 non-null   float64\n",
            " 4   Close      5385 non-null   float64\n",
            " 5   Adj Close  5385 non-null   float64\n",
            " 6   Volume     5385 non-null   float64\n",
            "dtypes: float64(6), object(1)\n",
            "memory usage: 294.9+ KB\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv(\"/content/kakao.csv\")\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "high_price = data['High'].values\n",
        "low_price = data['Low'].values\n",
        "\n",
        "mid_price = (high_price + low_price)/2"
      ],
      "metadata": {
        "id": "VlSJqfEd9lPT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "source": [
        "# timestep을 50으로 설정해서 데이터를 생성\n",
        "data_divideed = 50\n",
        "day_length = data_divideed + 1\n",
        "day_result = []\n",
        "\n",
        "for i in range(len(mid_price) - day_length):\n",
        "  day_result.append(mid_price[i: i + day_length])\n",
        "\n",
        "print(\"전체 데이터 length:\" , len(data))\n",
        "print(\"나눈 데이터 length:\" , len(day_result))\n",
        "print(day_result[0])\n",
        "print(day_result[1])"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERWzKgKIDj3K",
        "outputId": "1b4fa276-62ce-416e-e540-e2f30a8a2245"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 데이터 length: 5391\n",
            "나눈 데이터 length: 5340\n",
            "[54600. 53850. 47650. 44350. 50250. 48150. 42950. 41300. 36550. 39150.\n",
            " 41950. 38850. 37350. 36800. 36800. 32300. 30950. 29400. 31400. 33400.\n",
            " 36500. 33600. 29600. 28800. 29700. 27450. 23900. 21800. 23600. 22900.\n",
            " 22100. 22450. 23350. 21600. 20600. 22400. 19920. 17910. 17560. 18380.\n",
            " 19190. 21750. 21650. 19400. 19400. 17740. 15040. 14910. 14100. 12830.\n",
            " 13170.]\n",
            "[53850. 47650. 44350. 50250. 48150. 42950. 41300. 36550. 39150. 41950.\n",
            " 38850. 37350. 36800. 36800. 32300. 30950. 29400. 31400. 33400. 36500.\n",
            " 33600. 29600. 28800. 29700. 27450. 23900. 21800. 23600. 22900. 22100.\n",
            " 22450. 23350. 21600. 20600. 22400. 19920. 17910. 17560. 18380. 19190.\n",
            " 21750. 21650. 19400. 19400. 17740. 15040. 14910. 14100. 12830. 13170.\n",
            " 13380.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터 와 테스트 데이트 분할\n",
        "\n",
        "# 훈련 데이터 비율 설정\n",
        "train_data_rate = 0.9\n",
        "\n",
        "# 경계값 인덱스 구하기\n",
        "boundary = round(day_result.shape[0] * train_data_rate)\n",
        "\n",
        "train_data = day_result[:boundary, :]\n",
        "test_data = day_result[boundary:, :]\n",
        "\n",
        "print()"
      ],
      "metadata": {
        "id": "IB1wMhiZ-8Fz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3c51a27-ed77-40f7-b915-daefe18ce194"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import numpy as np"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "2YBb-YeCNLkd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "source": [
        "day_result = np.array(day_result)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "AF2bO1DBNL0D"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "source": [
        "# 훈련 데이터 와 테스트 데이트 분할\n",
        "\n",
        "# 훈련 데이터 비율 설정\n",
        "train_data_rate = 0.9\n",
        "\n",
        "# 경계값 인덱스 구하기\n",
        "boundary = round(day_result.shape[0] * train_data_rate)\n",
        "\n",
        "train_data = day_result[:boundary, :]\n",
        "test_data = day_result[boundary:, :]\n",
        "\n",
        "print()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcxtYsH-NMXr",
        "outputId": "edf5f0a3-7fea-4341-975a-81f3e40ee298"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 경계값 인덱스를 기준으로 훈련 데이터 와 검증 데이터 분할\n",
        "\n",
        "train_data = day_result[:boundary, :]\n",
        "test_data = day_result[boundary:, :]\n",
        "\n",
        "X_train = train_data[:, :-1]\n",
        "#\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "print(X_train.shape)\n",
        "\n",
        "y_train = train_data[:, -1]\n",
        "print(y_train.shape)\n",
        "\n",
        "X_test = test_data[:, :-1]\n",
        "X_test = np.reshape(X_test, (X_train.shape[0], X_train.shape[1], 1))\n",
        "y_test = test_data[:, -1]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "wB4yH1REMhZn",
        "outputId": "0dbcce8f-fbc6-4aed-9906-5a3d071d688e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4806, 50, 1)\n",
            "(4806,)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "cannot reshape array of size 26700 into shape (4806,50,1)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-e05e61451688>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    283\u001b[0m            [5, 6]])\n\u001b[1;32m    284\u001b[0m     \"\"\"\n\u001b[0;32m--> 285\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 26700 into shape (4806,50,1)"
          ]
        }
      ]
    },
    {
      "source": [
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GbVBhhTRRGY",
        "outputId": "b9a7f64a-fefe-44dc-8a17-a3f87c5a02d7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (4806, 50, 1)\n",
            "X_test shape: (534, 50)\n"
          ]
        }
      ]
    },
    {
      "source": [
        "if X_train.shape[1] != X_test.shape[1]:\n",
        "    raise ValueError(\"Inconsistent dimensions between X_train and X_test\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "47xy0keQRRbO"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "source": [
        "X_test = np.reshape(X_test, (X_train.shape[0], X_train.shape[1], 1))"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "M6e4VAIYRRvh",
        "outputId": "213d30e1-2353-4ebc-8e96-ba01dbe2f3de"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "cannot reshape array of size 26700 into shape (4806,50,1)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-615c29faccf4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    283\u001b[0m            [5, 6]])\n\u001b[1;32m    284\u001b[0m     \"\"\"\n\u001b[0;32m--> 285\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 26700 into shape (4806,50,1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NLP\n",
        "# 공통 코드\n",
        "# 차원 축소\n",
        "# 공통 코드\n",
        "import sys\n",
        "# sklearn ≥0.20 필수\n",
        "import sklearn\n",
        "# 공통 모듈 임포트\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "# 노트북 실행 결과를 동일하게 유지하기 위해\n",
        "np.random.seed(42)\n",
        "# 깔끔한 그래프 출력을 위해\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "import platform\n",
        "from matplotlib import font_manager, rc\n",
        "#매킨토시의 경우\n",
        "if platform.system() == 'Darwin':\n",
        "    rc('font', family='AppleGothic')\n",
        "#윈도우의 경우\n",
        "elif platform.system() == 'Windows':\n",
        "    font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
        "    rc('font', family=font_name)\n",
        "mpl.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# 그림을 저장할 위치\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"dim_reduction\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"그림 저장:\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "\n",
        "# 차원 축소\n",
        "# 공통 코드\n",
        "import sys\n",
        "# sklearn ≥0.20 필수\n",
        "import sklearn\n",
        "# 공통 모듈 임\n",
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "\n",
        "\n",
        "# 텍스트 전처리\n",
        "# 문장 토큰화\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk import sent_tokenize\n",
        "test_sample = '안녕하세요. 반갑습니다. 어서오세요! 환영합니다.'\n",
        "#. 나 !, ? 처럼 문장의 끝은 나타내는 기호나 \\n 단위로 분할해서 list 로 리턴\n",
        "sentences = sent_tokenize(text = test_sample)\n",
        "print(sentences)\n",
        "print(type(sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wh-JhQE7NSxw",
        "outputId": "e0c46707-337a-49ed-a429-4293c0faca71"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['안녕하세요.', '반갑습니다.', '어서오세요!', '환영합니다.']\n",
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# 토큰화 및 문장 인코딩\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "sentences = [\n",
        "    '영실이는 나를 정말 정말 좋아해',\n",
        "    '영실이는 영화를 무척 좋아해'\n",
        "]\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "# Access the word_index dictionary from the tokenizer object\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Print the tokenizer and word_index\n",
        "print(tokenizer)\n",
        "print(word_index)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjDG9o1VYkdD",
        "outputId": "bdc78864-7f00-4857-e023-dd0cd12d1fbc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.src.preprocessing.text.Tokenizer object at 0x79084d1837c0>\n",
            "{'영실이는': 1, '정말': 2, '좋아해': 3, '나를': 4, '영화를': 5, '무척': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장 인코딩\n",
        "word_encoding = tokenizer.texts_to_sequences(sentences)\n",
        "print(word_encoding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mthSqFAiYnVk",
        "outputId": "cf5bcab3-f3d3-47c9-fe35-4bd30e9b3923"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 4, 2, 2, 3], [1, 5, 6, 3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OOV - 사전에 없는 단어\n",
        "new_sequences = ['영실이는 아담을 좋아해']\n",
        "# 사전에 없는 단어는 기본적으로 무시됨\n",
        "word_encoding = tokenizer.texts_to_sequences(new_sentences)\n",
        "print(word_encoding)"
      ],
      "metadata": {
        "id": "WTVYzwBfZerJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "print('new_sentences' in globals())"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HFmyKvkZ22v",
        "outputId": "dbfff63d-a100-4b91-b793-c014824cf548"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "source": [
        "new_sentences = ['영실이는 아담을 좋아해']"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "7HCi5xtwZ3Ed"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "source": [
        "word_encoding = tokenizer.texts_to_sequences(new_sentences)\n",
        "print(word_encoding)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knjQMT3zZ3jq",
        "outputId": "a864a796-a72d-47c3-bc26-ec6394b976e4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(oov_token='<oov>')\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "print(tokenizer.word_index)\n",
        "\n",
        "word_encoding = tokenizer.texts_to_sequences(new_sentences)\n",
        "print(word_encoding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFAteBkcZ6Nn",
        "outputId": "597beccf-a566-4e2d-a3ab-08d2480cb45b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<oov>': 1, '영실이는': 2, '정말': 3, '좋아해': 4, '나를': 5, '영화를': 6, '무척': 7}\n",
            "[[2, 1, 4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(oov_token='<oov>', num_words = 3)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "print(tokenizer.word_index)\n",
        "# 문장을 인코딩 할 때 3개의 단어만을 사용하고 나머지는 모두 oov\n",
        "word_encoding = tokenizer.texts_to_sequences(new_sentences)\n",
        "print(word_encoding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ckPCWR9cO5f",
        "outputId": "7086d338-eec0-4d10-b381-96f746a3282d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<oov>': 1, '영실이는': 2, '정말': 3, '좋아해': 4, '나를': 5, '영화를': 6, '무척': 7}\n",
            "[[2, 1, 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 패딩 - 길이 맞추기\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "sentences = [\n",
        "    '영실이는 아담을 정말 정말 좋아해',\n",
        "    '영실이는 영화를 좋아해'\n",
        "]\n",
        "\n",
        "word_\n",
        "print(pad_sequences(word_encoding))\n",
        "\n",
        "print(pad_sequences(word_encoding, padding = 'post'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23y2vPe4dUos",
        "outputId": "9bec2d9c-5998-4b09-c160-1b81d1fb616a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2 1 1]]\n",
            "[[2 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 읽어오기\n",
        "train = pd.read_csv('', sep = \"\\t\")\n",
        "train.head()"
      ],
      "metadata": {
        "id": "XQhS14U8fi54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install konlpy"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neoER4YdgU4B",
        "outputId": "9c26c6d5-d624-436a-b713-795c96d52e44"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading JPype1-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m488.6/488.6 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.2)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.5.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import konlpy\n",
        "from konlpy.tag import Kkma, Komoran, Okt\n",
        "\n",
        "# Create an instance of the Okt tagger\n",
        "okt = Okt()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "PYfawjg-gVta"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text= \"시리야오늘날씨어때?\"\n",
        "# 형태소 분석을 수행해서 언어와 품사를 리턴\n",
        "print(Kkma.pos(text))\n",
        "print(komoran.pos(text))\n",
        "print(okt.pos(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "G8G-g02Qgbyn",
        "outputId": "6b5af27f-965f-48e7-e88f-753c7f1cabfb"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Kkma.pos() missing 1 required positional argument: 'phrase'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-a8a6f2301bc0>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"시리야오늘날씨어때?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 형태소 분석을 수행해서 언어와 품사를 리턴\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKkma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkomoran\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mokt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Kkma.pos() missing 1 required positional argument: 'phrase'"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install konlpy\n",
        "!pip install kss"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dayUfkkghG2w",
        "outputId": "3ec718d8-32e8-4156-984d-1ceffbb924a0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.5.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from konlpy) (4.9.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.10/dist-packages (from konlpy) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from JPype1>=0.7.0->konlpy) (23.2)\n",
            "Collecting kss\n",
            "  Downloading kss-4.5.4.tar.gz (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting emoji==1.2.0 (from kss)\n",
            "  Downloading emoji-1.2.0-py3-none-any.whl (131 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.3/131.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from kss) (2023.12.25)\n",
            "Collecting pecab (from kss)\n",
            "  Downloading pecab-1.0.8.tar.gz (26.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.4/26.4 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from kss) (3.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pecab->kss) (1.25.2)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from pecab->kss) (14.0.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from pecab->kss) (7.4.4)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (23.2)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (1.4.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (2.0.1)\n",
            "Building wheels for collected packages: kss, pecab\n",
            "  Building wheel for kss (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kss: filename=kss-4.5.4-py3-none-any.whl size=54464 sha256=93ff20964538b52fc78c414005ba2112371e6da4dffe475321b87aead7081472\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/7b/ba/e620ef5d96a61cdd83bdee4c2bb4aec8a74de5d72fcbb00e80\n",
            "  Building wheel for pecab (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pecab: filename=pecab-1.0.8-py3-none-any.whl size=26646665 sha256=dad7fe0f59ad4196114ae9c985f92336c4fd0b5e655cf6ef210509b1aef348bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/6f/b4/ab61b8863d7d8b1409def8ae31adcaa089fa91b8d022ec309d\n",
            "Successfully built kss pecab\n",
            "Installing collected packages: emoji, pecab, kss\n",
            "Successfully installed emoji-1.2.0 kss-4.5.4 pecab-1.0.8\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from konlpy.tag import Kkma, Komoran, Okt"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "zCsxuYjmhHOa"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "source": [
        "text = \"시리야오늘날씨어때?\"\n",
        "# 형태소 분석을 수행해서 언어와 품사를 리턴\n",
        "print(Kkma().pos(text))\n",
        "print(Komoran().pos(text))\n",
        "print(Okt().pos(text))"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwQkZu7bhHhL",
        "outputId": "26062847-d21e-4a49-b02d-49141aee2277"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('시', 'NNG'), ('리', 'NNG'), ('야', 'JX'), ('오늘날', 'NNG'), ('씨', 'NNB'), ('어', 'VV'), ('어', 'ECS'), ('때', 'NNG'), ('?', 'SF')]\n",
            "[('시', 'NNB'), ('리야', 'NNP'), ('오늘날', 'NNP'), ('씨', 'NNB'), ('어떻', 'VA'), ('어', 'EF'), ('?', 'SF')]\n",
            "[('시리', 'Noun'), ('야', 'Josa'), ('오늘날', 'Noun'), ('씨', 'Suffix'), ('어때', 'Adjective'), ('?', 'Punctuation')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 영어 와 한글만 남겨두고 삭제\n",
        "# 자연어를 이용해서 감성 분석 같은 작업을 할 떄 대부분의 경ㅇ우는 숫자를 제거\n",
        "train['document'] = train['document'].str.replace(\"[^A-Za-z가-힣ㄱ-ㅎ ㅏ - ㅣ]\", \"\")\n",
        "trian['document'].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "VK6ws9nJkK5m",
        "outputId": "e70c2aee-b352-4aa9-ea4d-ab101922958e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-519d95813842>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 영어 와 한글만 남겨두고 삭제\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 자연어를 이용해서 감성 분석 같은 작업을 할 떄 대부분의 경ㅇ우는 숫자를 제거\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'document'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'document'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[^A-Za-z가-힣ㄱ-ㅎ ㅏ - ㅣ]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrian\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'document'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.dropna()\n",
        "train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "ybxdYYEJk1Cj",
        "outputId": "12192142-b1bf-4bac-99ab-25f88381abd1"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-68a3bc033413>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "okt = Okt()\n",
        "\n",
        "def word_tokenization(text):\n",
        "  stop_words = ['는', '을', '를', '이', '와']\n",
        "  return [word for word in okt.morphs(text) if word not in stop_words]\n",
        "  # 형태소 분석 과 불용어 제거를 수행해서 문장을 단어의 list 로 변환\n",
        "data = train['document'].apply(lambda x : word_tokenization(x))\n",
        "data.head()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "nBmFtXdulGqS",
        "outputId": "ec669818-3222-4440-8ee2-8eb77708d0f8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-534a00e8fda0>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'는'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'을'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'를'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'이'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'와'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mokt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmorphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'document'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mword_tokenization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_size = 120000\n",
        "\n",
        "train_labels = train[\"label\"][:training_size]\n",
        "valid_labels = train[\"label\"][training_size:]"
      ],
      "metadata": {
        "id": "xG0eCvbWmMUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 토큰화 - 단어 사전을 만들고 문장을 숫자로 변환\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data)\n",
        "\n",
        "print(\"단어 개수:\", len(tokenizer.word_index))"
      ],
      "metadata": {
        "id": "d9U6-sBZm3xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5회 이상 등장하지 않은 단어 제거\n",
        "def get_vocab_size(threshold):\n",
        "  cnt = 0\n",
        "  for x in tokenizer.word_counts.values():\n",
        "    if x > threshold:\n",
        "      cnt = cnt+1\n",
        "  return cnt\n",
        "\n",
        "print(\"5회 이상 등장한 단어의 개수:\", get_vocab_size(5))"
      ],
      "metadata": {
        "id": "yLbX1LMwoVcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oov_tok = \"<oov>\"\n",
        "vocab_size = 15000\n",
        "\n",
        "tokenizer = Tokenizer(oov_token = oov_tok, num_words = vocab_size)\n",
        "tokenizer.fit_on_texts(data)\n",
        "print(\"단어 개수:\", len(tokenizer.word_counts))"
      ],
      "metadata": {
        "id": "IT1lEIUJowuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장을 숫자로 변경\n",
        "train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
        "valid_sequences = tokenizer.texts_to_sequences(valid_sentences)\n",
        "\n",
        "print(train_sentences[:3])\n",
        "print(train_sequences[:3])"
      ],
      "metadata": {
        "id": "SG5UtUHmpg_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장 길이를 전부 동일하게 만들기\n",
        "# 가장 긴 문장 길이를 확인\n",
        "max_length = max(len(x) for x in train_sequences)\n",
        "print(max_length)"
      ],
      "metadata": {
        "id": "pRuok0g2qqXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장 길이가 최대 길이보다 짧을 경우 0을 채울 위치와 최대 길이보다 긴 경우\n",
        "# 자를 위치를 설정\n",
        "trunc_type = 'post'\n",
        "padding_type = \"post\"\n",
        "\n",
        "train_padded = pad_sequences(truncating = trunc_type, padding = padding_type, maxien = max_length)\n",
        "valid_padded = pad_sequences(truncating = trunc_type, padding = padding_type, maxien = max_length)\n",
        "\n",
        "train_labels = np.asarray(train_labels)\n",
        "valid_labels = np.asarray(valid_labels)"
      ],
      "metadata": {
        "id": "7GA7SjIaqzXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원래는 아 더빙... 진짜 짜증나네요 목소리 텍스트 였는데 형태소 분석을 해서\n",
        "# 단어의 list 로 변경한 후 숫자로 변경하고 일정한 길이로 맞추는 작업을 수행\n",
        "print(train_sentences[:1])\n",
        "print(train_sequences[:1])\n",
        "print(train_padded[:1])\n"
      ],
      "metadata": {
        "id": "ZtD1Y40wrzw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jTeRBLcPsKMZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}